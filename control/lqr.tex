\FloatBarrier\section{LQR} \label{sec:lqr}

        \paragraph
        \gls{LQR} is a popular optimal control technique which has been shown to be an effective swing-damping controller for multirotors with a suspeneded payload 
        \cite{Erasmus2020} \cite{Slabber2020} \cite{Us2019}.
        \gls{LQG} combines this optimal control technique with a full-state estimator when all the satets cannot be measured \cite{Li2016}.
        An \gls{LQG} was effectiveley used by \cite{Slabber2020} for swing-damping control of a multirotor and suspended payload system.
        An \gls{LQR} for North velocity control with full-state feedback is presented in this section. 
        This controller structure can be duplicated for East veloicty control.
        
        \paragraph
        An \gls{LQR} does not inherently apply integral action and does not achieve zero steady-state tracking error in the presence of disturbacnes.
        Therefore the state vector is augmented with an integral state of the velocity error, $\mathcal{V}_N$, such that:
        \begin{equation}
            \dot{\mathcal{V}}_N = V_{N_{sp}} - V_N
        \end{equation}
        
        \paragraph
        The North velocity dynamics were derived and linearised in Chapter~\ref{chap:modelling} 
        to produce a state-space model which will be used to design the LQR.
        It is asumed that all model parameter are known before a flight, 
        except the payload paramaters, $l$ and $m_p$, which are estimated in the system identification phase.
        The augmented state space model which includes the integral state is given by:
        \begin{equation}
            \dot{\bm{x}}_A = \bm{A}_A \bm{x}_A + \bm{B}_A \bm{u}_A ,
        \end{equation}
        where
        \begin{align}
            \bm{x}_A &= 
                \begin{bmatrix}
                    \mathcal{V}_N & V_N & \theta & \dot{\theta}
                \end{bmatrix}^T, \\
            \bm{u}_A &= 
                \begin{bmatrix}
                    A_{N_{sp}}
                \end{bmatrix}, \\
            \bm{A}_A &= 
                \begin{bmatrix}
                    0 & -1 & 0 & 0 \\
                    0 & \frac{ -c_{air} }{m_Q} & \frac{ m_p \cdot g}{m_Q} & \frac{c_{\theta}}{(l\cdot m_Q)} \\
                    0 & 0 & 0 & 1 \\
                    0 & \frac{ c_{air} }{ (m_Q \cdot l) } & \frac{ (m_p+m_Q) \cdot g}{(m_Q \cdot l) } & \frac{ -c_{\theta} \cdot (m_p+m_Q)}{(l^2 \cdot m_Q \cdot m_p)}
                \end{bmatrix}, \mbox{ and} \\
            \bm{B}_A &= 
                \begin{bmatrix}
                    0 \\ 
                    \frac{1}{m_Q} \\
                    0 \\
                    \frac{-1}{(m_Q \cdot l)} \\
                \end{bmatrix}.
        \end{align}

        \paragraph
        The \gls{LQR} control law is defined as:
        \begin{equation} \label{eq:lqr_control_law}
            \bm{u}_A = \bm{K}_{lqr} ( \bm{x}_{A_{sp}} - \bm{x}_A ) ,
        \end{equation}
        where $\bm{K}_{lqr}$ is the \gls{LQR} gain, and $\bm{x}_{A_{sp}}$ is the augmented state vector setpoint.
        Only $V_{N_{sp}}$ has a non-zero value, hence 
        $\bm{x}_{A_{sp}} = \left[ 0~~V_{N_{sp}}~~0~~0 \right]^T$.
        
        \paragraph
        Furthermore, the \gls{LQR} considers the cost function:
        \begin{equation}\label{eq:lqr_cost_function}
            J( \bm{u}_A ) = \int_{0}^{ \infty } \left( \bm{X}_A^T \bm{Q} \bm{X}_A + \bm{u}_A^T \bm{R} \bm{u}_A \right) dt ,
        \end{equation}
        where $\bm{Q}$ is the state weighting matrix,
        and $\bm{R}$ is the input weighting matrix.
        The \gls{LQR} gain, $\bm{K}_{lqr}$, 
        is therefore determined by substituting Equation~\ref{eq:lqr_control_law} into Equation~\ref{eq:lqr_cost_function} and minimising the cost function.

        \paragraph
        The \gls{LQR} control performance can be manually tuned by changing the state and input weights in $\bm{Q}$ and $\bm{R}$ respectively.
        The weighting of each state variable can be weighted according to tracking importance.
        For example, if the weighting of $V_N$ is small in comparison to the weighting of $\theta$, 
        the controller will produce a slow velocity response with small payload swing angles.
        For the values in $\bm{R}$, if the weighting of an input variable is large, 
        the controller will output lower control values for that variable.

        \paragraph
        The general design requirements of the \gls{LQR} are to 
        produce a fast velocity response with zero-steady-state error while damping the payload oscillations quickly.
        The priority is to produce a smooth trajectory with minimal oscillation, however a reasonably fast response time is still required.
        An iterative tuning approach was used to determine the $\bm{Q}$ and $\bm{R}$ matrix entries that produce a good performance.
        The final \gls{LQR} veightings were selected as:
        \begin{equation}
            \bm{Q} = diag([0.1~~10~~0~~100]),~~~\bm{R} = 13 .
        \end{equation}
        Note that the weight of the payload angle variable is 0.
        This is because the payload angle will have a non-zero steady-state value at constant velocity, $V_N$, due to aerodynamic drag.
        The payload angle is therefore damped by placing a heavy weighting on the derivative of the payload angle instead.

        \input{control/plots/lqr_tuning_plot.tex}

        \paragraph
        Figure~\ref{fig:lqr_tuning_plot} shows a plot of the simulated \gls{LQR} velocity response with different payload parameters.
        It is clear that the controller damps the payload angles well and produces a smooth trajectory with different payloads.
        The same matrixes weighting are used 
        For each different payload, 
        the payload parameters are estimated, 
        the state-space model is populated, 
        and the \gls{LQR} gain is calculated using the same weighting matrix values.
        The controller performance, including disturbance rejection, will be further discussed in Section~\ref{sec:control_implementation}.

    

    