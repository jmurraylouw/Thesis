\section{Implementation and results}

    In order to test the system identification techniques,
    numerous simulations were performed to investigate their performance 
    with different system configurations.
    Firstly, the influence of design parameters on the algorithm performance are explored.
    These parameters include hyperparameters, the length of training data and the algorithm sample time.
    The effect of conditions that are not determined by algorithm design are also explored, 
    like measurement noise, and the physical properties of the payload.
    Finally, the white-box and black-box techniques are tested on a dynamic payload 
    which does not satisfy the assumptions of a simple pendulum.

    \subsection{Methodology}

        \paragraph{Simulation environment}
        A SITL implementation of PX4 \cite{Meier2015} using the Gazebo simulator \cite{Koenig2004} is used to generate data
        for system identification.
        Testing these techniques with simulation data allow us to investigate a much larger range system configurations 
        than possible with practical flights.
        The simulation model used in Gazebo was verified in Chapter~\ref{chap:modelling}.
        Using PX4 in SITL also ensures that the controller dynamics in simulation 
        is as close as possible to practical flights since the same flight stack is used in both cases.
        Gazebo also applies realistic measurement noise to the signals received by PX4, 
        which applies an EKF for state estimation.
        Therefore the the data seen by the system identification techniques 
        will also include the filtering effect of the EKF as it would in practical flights.

        \paragraph{Method overview}
        The procedure used to evaluate the black-box techniques is as follows:
        \begin{enumerate}
            \item Takeoff and hover with the qaudrotor
            \item Start logging input and output data
            \item Command a series of velocity step setpoints with random step sizes and time intervals
            \item Stop logging data
            \item Split data into separate training and testing periods
            \item Build a model from the training data
            \item Calculate a error metric for the model from the testing data
        \end{enumerate}

        \paragraph{PID gains}
        The default PID velocity controller from PX4 is used during these simulation.
        The implemented controller gains are documented in Appendix~\ref{appen:pid_gains}.
        A ROS node is used to read and log the payload angle measurement from Gazebo and a different
        ROS node is used to send the velocity setpoints to PX4 
        through the MAVLink protocol with the ROS package, 'mavros'.

        \paragraph{Steps and intervals}
        A algorithm schedules the series of velocity step commands 
        by assigning random step values and time-intervals within a specified range.
        Theses values are selected from a uniform distribution 
        within the ranges specified in Table~\ref{tbl:input_ranges}
        The maximum velocity step is determined in simulation by iteratively increasing the maximum velocity step 
        to a safe value where the quadrotor remains in stable flight
        and the payload angles do not swing out of control.
        The time interval range is set iteratively to ensure 
        that the generated data includes both transient and steady-state dynamics.
 
        \begin{table}[!h]
            \renewcommand{\arraystretch}{1.1}
            \centering
            \caption{Input data ranges.}
            \begin{tabularx}{0.65\linewidth}{@{}lCCr@{}}
                \toprule
                         & Velocity step [\SI{}{\metre/\second}]  & Step time interval [\SI{}{\second}]\\
                \midrule
                Minimum  & 0                                    & 10\\
                Maximum  & 3                                    & 25\\
                \bottomrule
            \end{tabularx}
            \label{tbl:input_ranges}
        \end{table}
        
        \input{system_id/plots/training_data.tex}

        \paragraph{}
        Figure~\ref{fig:training_data} 
        shows an example of random velocity steps and the resulting velocity response used as training data.
        Using random velocity steps and time intervals prevents the system identification methods 
        from overfitting to a specific set of control conditions.
        The method should rather determine a generalised model 
        that works over a range of possible control conditions.

        \paragraph{}
        The data logged from simulation is then divided into testing and training data.
        The training data is used by the system identification algorithms to generate a regression model 
        and the model is then used to determine a prediction error metric over the unseen testing data.
        It is common practice in model evaluations 
        to use separate sets of data for training and testing.
        This ensures that good predictions scores do not result from models that overfit to the training data. 
        
        \paragraph{}
        The testing data spans a fixed length of time and taken from the start of the simulation period.
        The training data is then allocated from the remainder of the data.
        The same testing data is used to calculate error metrics for different models with different configurations
        to ensure that the metric for each model is comparable. 
        This error metric calculated from the testing data is used to evaluate and rank the performances of different models.       

        % \paragraph{Why velocity steps?}
        % As discussed before, the purpose of identifying a data-driven model of the plant dynamics 
        % is to use it in a MPC controller in the velocity loop, 
        % therefore velocity inputs are used in the system identification process.
        % It is a common technique to use a step responses for system identification \cite{Chen2011} because it exposes a 
        % large range of frequency data in the system dynamics.
        % In other data-driven techniques like Neural-Nets, it may be helpful to use a larger variety of input types.
        % The input schedule may be generated by randomly switching between step, ramp and exponetional inputs 
        % to further gaurd againts overfitting \cite{Kotze2021}.
        % However, for the 
        % In practice it is more common to command position step setpoints since a quadrotor delivers

    \subsection{Error metric}

        \paragraph{}
        It was decided to use an error metric based on predictions accuracy over a time horizon to quantify the performance of different models.
        The prediction accuracy of the identified model is important 
        because it will used for control optimisation over a prediction horizon in a discrete MPC.
        Common error metrics used for regression models are MSE and MAE.
        MSE penalises larger errors more than smaller errors, whereas MAE penalises all errors equally.
        It was decided to use MAE because it provides a more intuitive error value than MSE 
        and there is no motivation to penalise larger errors more in the measure of prediction accuracy for our use case.
        MAE is calculated as:
        % \begin{equation}
        %     \bm{MAE} = \frac{1}{N_{run}} \cdot \sum_{k = 1}^{N_{run}} \left\lvert \bm{\hat{x_k}} - \bm{x_k} \right\rvert ,
        % \end{equation}
        \begin{equation}
            \bm{MAE} = mean \left( \phantom{.} \left\lvert \bm{\hat{x_k}} - \bm{x_k} \right\rvert \phantom{.} \right),
        \end{equation}
        where 
        % $N_{run}$ is the number of samples used in the prediction run,
        $\bm{x_k}$ is the actual state vector at time-step $k$, 
        $\bm{\hat{x_k}}$ is the state prediction, 
        and 
        $\bm{MAE}$ is a vector with the MAE of each state.

        % \paragraph{}
        % Other considered error metrics are IAE and ITAE which adds up error over the prediction period.
        % IAE integrates the absolute error over time and weights all error equally.
        % ITAE integrates the absolute error multiplied by time over time 
        % hence errors that occur later in the prediction are weighted more than those that that occur earlier.
        % MAE was chosen over these metrics 
        % since it is closer to the loss function of the MPC than IAE or ITAE.
        % Especially, ITAE achieves the opposite of what is desired because it penalises earlier errors less.
        % For the MPC it is more important that early prediction errors are small since it will reoptimise later  

        \paragraph{}
        Other metrics which are more statistically rigorous in model selection 
        than these error metrics are AIC and BIC.
        These metrics are information criteria scores which compute the maximum log likelihood of the model 
        and add a penalty based on the number of terms in the model.
        Thereby they provide a quantitative way of performing a Pareto analysis, 
        which aims to balance model complexity with model accuracy \cite{Mangan2017}.
        It is generally better to use a parsimonious model, 
        which has a low prediction error but is not overly complex.
        This not only helps to avoid overfitting, but also ensure that the MPC optimisation problem 
        is not too computational expensive for the available hardware and desired control frequency.
        
        \paragraph{}
        However, computing the maximum log likelihood of each model involves numerous simulations per model.
        This is computationally intractable and unpractical for model selection in our case 
        since there is such a large number of hyperparameter combinations to compare, as explained in Section~\ref{sec:hyperparameters} 
        Therefore MAE will be used to evaluate model performance, 
        because it provides a good measure of a model prediction 
        and it is computationally fast enough to perform for wide hyperparameter search.
        AIC or BIC may be able to identify a slightly better model, 
        but when used with the MPC this slight improvement in prediction accuracy 
        will result in a negligible improvement in control performance

        \paragraph{}
        The prediction MAE of one model may differ significantly 
        depending on the starting condition and length of prediction horizon
        The prediction horizon used for the MAE is selected as \SI{20}{\second}
        and is significantly longer than the desired MPC prediction horizon.
        This ensures that models which may be marginally unstable are penalised heavily and are discarded in model selection. 
        Some models have very accurate transient predictions, but prove to be unstable over a longer time horizon.
        If the prediction horizon of the MAE is too short, these models may unreasonably high.
        These models could result in unstable control at certain control conditions and are a safety hazard.

        \murray{Maybe insert example of good initial prediction but bad long term ??}

        \paragraph{}
        Different starting conditions also have a large influence on the prediction score of a model.
        Some models may have accurate predictions of transient behaviour, 
        while being extremely bad at steady-state predictions.
        This would result in an MPC controlling the plant well during the initial step response,
        but becoming unstable during steady-state control.
        In order to have a MPC that can control the plant during the different stages of a flight, 
        a model needs to be selected with accurate predictions over a range of different control conditions.
        
        \paragraph{}
        Therefore the error metric needs to include predictions from multiple starting conditions in the testing data.
        The resulting testing procedure is to first specify a number of equispaced starting conditions within the testing data.
        The model is then run multiple times for the length prediction horizon, stating with different initial conditions each time.
        The MAE is determined for each run whereafter the average of these scores gives the final MAE score of the model.
        In order to balance the variety of testing conditions with the computational time per error metric calculation, 
        10 was selected as the number of different initial conditions use in the final MAE score. 
        
        \paragraph{}
        The MAE of each state variable is calculated individually.
        These cannot easily be combined into a single error value 
        because the states have different units and different orders of magnitude.
        However a single value is required to rank the overall prediction performance of different models 
        and quantitatively select a model.
        Therefore a weighted average of the MAE of each state is used as a single value 
        to represent the prediction accuracy of the model.
        This value is calculated as:
        % \begin{equation}
        %     metric = \frac{1}{n_x} \cdot \sum_{i = 1}^{n_x} \left( \frac{ \bm{MAE_i} }{ x_{i, max} } \right) 
        % \end{equation}
        \begin{equation}
            metric = mean \left( \frac{ \bm{MAE_i} }{ x_{i, max} } \right) 
        \end{equation}
        where 
        % $n_x$ is the number of states,
        $\bm{MAE_i}$ is the MAE of the $i$\textsuperscript{th} state,
        and
        $x_{i, max}$ is the maximum absolute value of the $i$\textsuperscript{th} state in the testing data.

        Explain what metric is now? in percentage??
        Change csv plots to use scale by non-square root and see effect
        Try use MASE?? https://towardsdatascience.com/mad-over-mape-a86a8d831447

        This is the final error metric used to evaluate the model predictions 
        in the sections to follow.

        % \paragraph{}
        % Each state error signal is scaled by the reciprocal of the maximum value of that state variable in the training data.
        % % This is to provide a better representative error when taking the mean of state variable errors.
        % This is to ensure that a scale difference in the variable types create a bias in the error metric.
        % For example, the quadrotor velocity reaches values of \SI{3}{\metre/\second} but the payload swing angle has a maximum of only \SI[]{0.526}{\radian}.
        % The velocity prediction error is therefore inherently larger than the payload angle prediction error
        % and will bias the error metric towards favouring models with good velocity predictions.
        % The proposed scaled error metric ensures that the MAE of each state variable can be compared to each other.
        % It also provides an error metric that is better and unbiased representative of the model prediction performance across all state variables. 

    \subsection{Hyperparameters} \label{sec:hyperparameters}
        As discussed in Section~\ref{sec:dmdc} and \ref{sec:havok} 
        DMDc and HAVOK are dependent on two hyperparameters: the number of delay-coordinates, $q$, and the SVD truncation rank, $p$.

        Parsimony
        Pareto front
        cite Data-Driven book

        The more terms better chance to overfit, lower generalisation
        \input{system_id/plots/MAE_vs_q.tex}

        \input{system_id/plots/singular_values.tex}

        Fixed size of data
        Fixed sample time
        Fixed pendulum params
        Talk about the "front"
        Also about singular values
        For each of the experiments shown in this chapter, a hyperparameters selected tuned to produced

    \subsection{Sample time}
        The sample time, $T_s$, used for system identification sets the sample time of the discrete model, 
        which determines the sample time of the MPC.
        Resampling strategies can enable the MPC to run at a different frequency to the discrete model but this adds unnecessary complexity to the control architecture.
        
        \paragraph{}
        The MPC acts in the velocity loop and commands an acceleration setpoint.
        The default PID velocity controller runs at \SI{50}{\hertz} which corresponds to $T_s =~$\SI{0.02}{\second}.
        Due to the computational complexity of an MPC, the optimiser will struggle to run at \SI{50}{\hertz} on a quadrotor companion computer.
        \input{system_id/plots/MAE_vs_Ts_vs_L.tex}
        This is because the  
        % \input{system_id/plots/MAE_vs_Ts.tex}

    \subsection{Choice of payload variable in the state vector}
        As discussed in Section~\ref{sec:plant_considered}, 
        the equations of motion of a floating pendulum in continuous-time are dependent on $\dot{\theta}$ and $V_N$, 
        but are not dependent on $\theta$.
        Therefore it is expected that 
        $
        \bm{x} = \begin{bmatrix}
            V_N & \dot{\theta}
        \end{bmatrix}^T
        $
        is used as the state vector for system identification.
        However, if $\dot{\theta}$ is not included in the state vector of a discrete model, 
        it can still be represented with numerical differentiation like the backward Euler form,
        \begin{equation}
            \dot{\theta}_k = (\frac{1}{T_s}) \cdot \theta_k - (\frac{1}{T_s}) \cdot \theta_{k-1} .
        \end{equation}
        Therefore the original state vector can also be replaced by,
        $
            \bm{x} = \begin{bmatrix}
                V_N & \theta
            \end{bmatrix}^T
        $
        in system identification.

        \paragraph{}
        Based on the floating pendulum equations, it is expected that a model derived with $\dot{\theta}$ data 
        will better approximate the actual dynamics than one using $\theta$.
        This is because $\dot{\theta}$ contains more direct information about the dynamics compared to $\theta$.
        A model using $\theta$ needs to "learn" numerical differentiation and the effect of $\dot{\theta}$ on the other variables.
        A model using $\dot{\theta}$ only needs to consider its relationship with other variables.

        \input{system_id/plots/different_state_vectors.tex}

        \paragraph{}
        % Figure~\ref{} shows the prediction error of techniques using $\dot{\theta}$ or $\theta$ for different amounts of training data.
        For each length of training data, the hyperparameter combination producing the lowest prediction error was determined and used.
        From this plot it is clear that models with $\theta$ produce more accurate predictions than those with $\dot{\theta}$.

    \subsection{Noise}
        \paragraph{}
        Measurement noise is \murray{Find reference for measurement noise definition}
        This is bad for system identification because the output signals no longer represent the actual process
        hides the actual dynamics of the system under  
        The IMU, barometer, magnetometer and GPS sensors on the practical quadrotor are used for state estimation 
        and all experience measurement noise.
        The EKF performs sensor fusion and smooths out most of the measurement noise to provide a state estimate that is less noisy than raw sensor values.
        
        \paragraph{}
        The potentiometer and ADC which measure the payload angle on the quadrotor alos has quite a lot of measurement noise.
        However, this signal is not smoothed by an onboard EKF.
        Figure~\ref{fig:payload_noise} shows the noisy payload angle measurement for a practical pendulum test while the quadrotor is held stationary.
        For models using $\theta$ in the state vector instead of $\dot{\theta}$, 
        this noisy signal can be smoothed with \murray{matlab smoother}.
        Figure~\ref{fig:payload_noise_smoothed} compares the noisy payload angle measurement to the smoothed signal and actual payload angle for a simulated flight.
        The is applied as band-limited white-noise and the noise power was iteratively adjusted to match that of the practical payload measurements.
        
        \paragraph{}
        However, since there is no direct measurement of $\dot{\theta}$, 
        numerical differentiation is performed on the noisy $\theta$ measurement to estimate $\dot{\theta}$. 
        This amplifies the noise and results in inaccurate $\dot{\theta}$ signal.
        Total variation differentiation is implemented to estimate $\dot{\theta}$ from the noisy measurements more accurately.
        Figure~\ref{fig:payload_noise_diff} shows
        
        % \input{system_id/plots/payload_noise_diff.tex} // With TVDiff

        Noise also affects model prediction accuracy and the length of training data required for adequate predictions. 
        
        \input{system_id/plots/noise_vs_no_noise.tex}

        \input{system_id/plots/havok_vs_dmd_noise.tex}

        HAVOK performs better than DMD.
        This slight difference in prediciton performance has a negligible effect on control.
        

        \murray{Input data needs to be adjusted.}
        \murray{What about disturbances}
        % \input{plot of SITL acc_sp}
    

    \subsection{Size of training data}
        The length of training data used for system identification affects the quality of the model produced.
        In Figure~\ref{fig:SITL_MAE_vs_train_angular_rate} it is clear that prediction error decreases as the amount of training data increases.
        As more training data is used in the regression problem, 
        the determined model better approximates the actual dynamics because a large range of the dynamics is "seen" by the algorithm.
        
        % \input{low data prediction}
        \paragraph{}
        Models produced from data lengths as short as \SI{5}{\second} predict the movement of state variables surprisingly well.
        % Figure~\ref{} shows prediction.
        Note how the general shape of the prediction represents the training data, 
        even though it contains a lot more high frequency oscillations.

        \input{system_id/plots/MAE_diff.tex}

        \paragraph{}
        % Figure~\ref{} shows the MAE of prediction state derivative.
        Define MAE diff with equation ??.
        % From Figure~\ref{} it appears that at least \SI{}{} training data is required to produce models that represent the dynamics.

        \paragraph{}
        The models produced from HAVOK appear to produce slightly better prediction errors, however this small difference has a negligible effect on control performance.

        \paragraph{}
        % In Figure~\ref{fig:MAE_vs_train} it can be seen that after approximately \SI{??}{\second} 
        the prediction error does not significantly improve with more training data.
        It practice less training data is desirable because less flight time will be wasted on training a model before the quadrotor can fly with a updated controller.
        Less training data also corresponds to lower memory usage on quadrotor hardware.
        Such a slight improvement in prediction error also has a negligible effect on control performance and is therefore not worth the increased data requirement.
        % Therefore, only \SI{??}{\second} of flight data will be used to train system identification models. 


    \subsection{System parameters}
            
        Works across a range of parameters.

        \paragraph{}
        The payload acting as a single floating pendulum, as described in Section~\ref{sec:plant_considered},
        has two system parameters, $m_p$ and $l$.
        For the practical quadrotor considered, the payload mass is limited to:
        \begin{equation}
            0.01 \leq m_p \leq \SI{0.4}{\kilo\gram} .
        \end{equation}
        When no external payload is attached, the connection device attached to the end of the cable is 
        $m_p = \SI{0.01}{\kilo\gram}$.
        % It becomes unsafe to Flying without a cable attached to the cable, or with a payload with a very small mass, 
        % may become unsafe since the cable may not always  kept taut by the mass. 
        On the other limit, $m_p = \SI{0.4}{\kilo\gram}$ is determined to be the maximum payload mass the quadrotor can carry safely 
        based on the maximum thrust of the motors.

        \paragraph{}
        The cable length is limited to:
        \begin{equation}
            0.5 \leq l \leq \SI{2}{\metre} .
        \end{equation}
        A cable length shorter than \SI{0.5}{\metre} is quite impractical and may rather be attached as a rigid payload.
        There are very few practical applications that may require a shorter cable length.
        It is also unsafe to fly with a shorter cable length, 
        since the payload may collide with the quadrotor during an uncontrolled swing.
        A longer cable guards against a payload and vehicle collision, 
        because more energy needs to be transferred to the payload to reach the height of the vehicle. 
        The maximum cable length is selected as $l=~\SI{2}{\metre}$ by intuition 
        since a cable much longer than this may not be practically useful for a drone delivery flight with the considered quadrotor.

        \paragraph{}
        Plot MAE vs l
        \input{system_id/plots/MAE_vs_Ntrain_vs_L_havok.tex}
        DMD shows the same trend revealed in Figure~\ref{fig:MAE_vs_Ntrain_vs_L_havok}.

        \paragraph{}
        Plot MAE vs m
        \input{system_id/plots/MAE_vs_Ntrain_vs_m_havok.tex}
        DMD shows the same trend revealed in Figure~\ref{fig:MAE_vs_Ntrain_vs_m_havok}.

        \paragraph{}
        % Not very conclusive
        % \input{system_id/plots/MAE_vs_Ts_vs_L.tex}
        % See how it affects Ts
        % plot MAE vs Ts with contours of l

        Best hyperparameters.
        Fixed size of data.
        Fixed sample time.

    \subsection{Dynamic payload}
        Some payloads attached to the cable may not satisfy the assumptions made in Section~\ref{sec:plant_considered}.
        For example, if a long payload is attached to the cable, the CoM of the payload will be quite a distance below the attachment of the cable.
        This creates a double pendulum model with dynamics that differ significantly from a single pendulum.
        Figure~?? shows a practical double pendulum use case. 
        In 2D this payload is better represented by the floating double pendulum modelled in Figure~??.

        \murray{insert picture a practical quad with long payload}
        \murray{insert diagram of double pend}
        
        \paragraph{}
        It is a non-trivial task to compare the data-driven models with the white-box models,
        because they are different forms and are used in different types of controllers.
        The a white-box system identification technique determines a continuous state space model 
        which is used in an LQR controller. 
        This is in the form:
        \begin{equation}
            \dot{x} = A x + B u
        \end{equation}
        For this model, it is important that the time-derivative estimate of the model 
        at the current time-step 
        is similar to the actual time-derivative of the system state at that time-step.
        The LQR controller applies an gain to the current state estimate 
        to determine the input signal at that time-step only.
        Hence, the state prediction for multiple time-steps into the future is not as important.

        \paragraph{}
        In contrast, the data-driven techniques result in a discrete state space model,
        \begin{equation}
            x_{k+1} = A x_k + B u_k ,
        \end{equation} 
        which is used in a MPC.
        Therefore the prediction accuracy of the model for multiple time-steps over a time horizon is important,
        since the MPC optimises the control input based on this state prediction.
        
        \paragraph{}
        Even though the models cannot easily be compared to each other, 
        the performance of the controllers using these models can be compared.
        This comparison will be investigated in % Chapter~\ref{chap:}

        \paragraph{}
        For single pend
        plot theta prediction dmd vs havok va white-box

        Note that the payload oscillations are damped slightly by the PID controller.
        It appears that this damping is more complex than the linear damping model 
        used to model the white-box model, since the actual swing amplitude 
        does not linearly decrease as expected.
        The damping effect is a function of the controller gains, 
        the payload connection and the aerodynamic drag of the payload.
        An advantage of the data-driven system identification techniques 
        is that the effect of damping is inherently included in the estimated model 
        without specifically estimating it.
        In contrast, the white-box estimation technique requires a designed algorithm 
        to estimate every parameter that effects the dynamics, 
        namely the payload mass, cable length and damping coefficient


        \paragraph{}
        \input{system_id/plots/prediction_single_pend_black.tex}
        \input{system_id/plots/prediction_single_pend_white.tex}
        
        \input{system_id/plots/prediction_double_pend_black.tex}
        \input{system_id/plots/prediction_double_pend_white.tex}
        
        \input{system_id/plots/FFT_amplitude_single_pend.tex}
        The FFT of the single pendulum leads to an estimated cable length of \SI{1.19}{\metre}        

        \input{system_id/plots/FFT_amplitude_double_pend.tex}
        The FFT of the double pendulum leads to an estimated cable length of \SI{1.39}{\metre}
        
        \paragraph{}
        Since the a priori white-box model is based on a single pendulum model, 
        the dynamics described by the model are significantly different from the actual dynamics.
        This will have a detrimental effect on the control performance of a controller based on such a model,
        since the controller will be designed for different plant than what it is controlling actually controlling.
        
        \input{system_id/plots/MAE_vs_Ntrain_double_pend}

        \paragraph{}
        For each of these payload cases, a different parameter estimation based techniques would needs to be designed for effective control.
        This is undesirable for practical drone deliveries, especially when the type of paylaod is not known well in advance or changes regularly.
        A data-driven technique provides a more general solution since it accommodates a larger range of payload types and does not require a prioir modelling information.
        
        plot hyperparameterss MAE. Not how much more delays are required
        
        Takens theorum.
        Add DMD to plot
        \input{system_id/plots/MAE_vs_q_double_pend}

        \paragraph{}
        The double pendulum is one example of a payload case that would require a redesign of the control architecture.
        Other dynamic payloads that are difficult to model with a white-box method are containers holding a fluid.
        Examples: 

        \paragraph{}
        Another payload case that will cause inaccuracies in estimated white-box model 
        is if a payload is attached rigidly to the quadrotor while also carrying a suspended payload.
        The payload mass estimation is based on the assumption that the quadrotor mass is known.
        However if a mass is rigidly attached to the vehicle, the effective quadrotor mass is changed and the RLS payload mass estimation is no longer accurate.

